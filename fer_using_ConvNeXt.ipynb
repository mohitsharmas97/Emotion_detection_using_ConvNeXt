{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkar-hue/Emotion_detection_using_ConvNeXt/blob/main/fer_using_ConvNeXt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3KmsaNXpIJo"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /kaggle/input/fer2013/"
      ],
      "metadata": {
        "id": "t_COIqgDrCwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "r-Nm3MgYrEc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "PdIP7KfSrGII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through(path)"
      ],
      "metadata": {
        "id": "y8bAM2IDrKc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "YMFrvtxFrMVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/kaggle/input/fer2013/train'\n",
        "test_dir = '/kaggle/input/fer2013/test'\n"
      ],
      "metadata": {
        "id": "3sqB5ZCurOeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "DEwNzbLMrqYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For training with augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# For testing (no augmentation)\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "OSgK4-jOrl52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n"
      ],
      "metadata": {
        "id": "a5nntFY-rndm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "Jq3_hvSzrwAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.classes\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "id": "uns5418Yrygp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_dataset.classes\n",
        "\n",
        "class_name"
      ],
      "metadata": {
        "id": "c8LoArrfr06a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_idx = train_dataset.class_to_idx\n",
        "\n",
        "class_idx"
      ],
      "metadata": {
        "id": "Rx2HYzU6r5r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "RsgliUrGsAA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "weights = torchvision.models.EfficientNet_B3_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b3(weights=weights)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Qmi6DVAmr7rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze more layers\n",
        "for layer in list(model.features)[-5:]: # Try -8 or -10 instead of -5\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True"
      ],
      "metadata": {
        "id": "6UY_u9par-xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "\n",
        "output_shape = len(train_dataset.classes)\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.3, inplace=True),\n",
        "    torch.nn.Linear(in_features=1536,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "id": "PePDgEuSsHSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)"
      ],
      "metadata": {
        "id": "1IPWH5U1sJKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=2\n",
        ")"
      ],
      "metadata": {
        "id": "I5B4rJYUsOCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device,\n",
        "               scheduler: torch.optim.lr_scheduler._LRScheduler = None) -> Tuple[float, float]:\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() * X.size(0)  # Scale loss by batch size\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(loss)  # Step the scheduler if provided\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"LR: {current_lr:.6f}\")\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "    train_loss /= total_samples  # Normalize by total dataset size\n",
        "    train_acc /= total_samples  # Normalize accuracy\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "uXZksREbsRrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "fipTYNb0sV67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       criterion,\n",
        "                       optimizer,\n",
        "                       device,\n",
        "                       num_epochs=50,\n",
        "                       patience=5,\n",
        "                       checkpoint_dir='./checkpoints',\n",
        "                       scheduler=None): # Add scheduler argument\n",
        "    \"\"\"\n",
        "    Train and validate the model with early stopping and checkpointing\n",
        "\n",
        "    Args:\n",
        "    - model: PyTorch model\n",
        "    - train_loader: DataLoader for training data\n",
        "    - val_loader: DataLoader for validation data\n",
        "    - criterion: Loss function\n",
        "    - optimizer: Optimizer\n",
        "    - device: Computing device (cuda/cpu)\n",
        "    - num_epochs: Maximum number of training epochs\n",
        "    - patience: Number of epochs with no improvement after which training will be stopped\n",
        "    - checkpoint_dir: Directory to save model checkpoints\n",
        "    - scheduler: (Optional) Learning rate scheduler\n",
        "    \"\"\"\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Training history tracking\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_acc = 0, 0\n",
        "\n",
        "        train_progress_bar = tqdm(train_loader,\n",
        "                                  desc=f'Epoch {epoch+1}/{num_epochs}',\n",
        "                                  unit='batch')\n",
        "\n",
        "        for batch, (X, y) in enumerate(train_progress_bar):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute metrics\n",
        "            train_loss += loss.item()\n",
        "            train_pred = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "            train_acc += (train_pred == y).float().mean().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            train_progress_bar.set_postfix({\n",
        "                'Train Loss': loss.item(),\n",
        "                'Train Acc': train_acc / (batch + 1)\n",
        "            })\n",
        "\n",
        "        # Average epoch metrics\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_acc = 0, 0\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_pred = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "                val_acc += (val_pred == y).float().mean().item()\n",
        "\n",
        "        # Average validation metrics\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc /= len(val_loader)\n",
        "\n",
        "        # Store history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Step the scheduler with the validation loss\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "            print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping and model checkpointing\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss\n",
        "            }, os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "            break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "mPC2H2afsXcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_and_validate(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        num_epochs=6,\n",
        "        patience=3,\n",
        "        checkpoint_dir='/kaggle/working/checkpoints'\n",
        "    )"
      ],
      "metadata": {
        "id": "kwxMlieHsZL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba6a00af"
      },
      "source": [
        "import shutil\n",
        "\n",
        "# 1. Define paths to original directories\n",
        "original_train_dir = '/kaggle/input/fer2013/train'\n",
        "original_test_dir = '/kaggle/input/fer2013/test'\n",
        "\n",
        "# 2. Create new directories\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "os.makedirs(filtered_train_dir, exist_ok=True)\n",
        "os.makedirs(filtered_test_dir, exist_ok=True)\n",
        "\n",
        "# 3. Define classes to keep\n",
        "classes_to_keep = ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# 4. Write a function to copy filtered data\n",
        "def filter_and_copy_data(original_dir, new_dir, classes):\n",
        "    for class_name in classes:\n",
        "        # Create class subdirectory in the new directory\n",
        "        new_class_dir = os.path.join(new_dir, class_name)\n",
        "        os.makedirs(new_class_dir, exist_ok=True)\n",
        "\n",
        "        # Path to the original class subdirectory\n",
        "        original_class_dir = os.path.join(original_dir, class_name)\n",
        "\n",
        "        # Copy all images from the original to the new directory\n",
        "        for filename in os.listdir(original_class_dir):\n",
        "            shutil.copy(os.path.join(original_class_dir, filename), new_class_dir)\n",
        "\n",
        "# 5. Call the function for both training and testing datasets\n",
        "filter_and_copy_data(original_train_dir, filtered_train_dir, classes_to_keep)\n",
        "filter_and_copy_data(original_test_dir, filtered_test_dir, classes_to_keep)\n",
        "\n",
        "print(\"Filtered datasets created successfully.\")\n",
        "walk_through(filtered_train_dir)\n",
        "walk_through(filtered_test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d71cca0"
      },
      "source": [
        "# 1. Create a new ImageFolder dataset for the filtered training data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_train_dataset = datasets.ImageFolder(root=filtered_train_dir, transform=train_transforms)\n",
        "\n",
        "# 2. Extract the class names and class-to-index mapping\n",
        "filtered_class_names = filtered_train_dataset.classes\n",
        "filtered_class_idx = filtered_train_dataset.class_to_idx\n",
        "\n",
        "print(\"Filtered Classes:\", filtered_class_names)\n",
        "print(\"Filtered Class Index Mapping:\", filtered_class_idx)\n",
        "\n",
        "# 3. Update the output_shape variable\n",
        "output_shape = len(filtered_class_names)\n",
        "print(\"Updated output shape:\", output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nContinuing training with a lower learning rate...\")\n",
        "continued_optimizer = optim.Adam([\n",
        "    {'params': model_b0.features.parameters(), 'lr': 2e-6},  # Was 1e-5\n",
        "    {'params': model_b0.classifier.parameters(), 'lr': 2e-5}   # Was 1e-4\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# 3. Set up a new scheduler for the new optimizer\n",
        "continued_scheduler = ReduceLROnPlateau(continued_optimizer, 'min', patience=2, verbose=True)\n",
        "\n",
        "# 4. Train for 5 more epochs\n",
        "history_continued = train_and_validate(\n",
        "    model=model_b0,\n",
        "    train_loader=train_loader_b0,\n",
        "    val_loader=test_loader_b0,\n",
        "    criterion=criterion,\n",
        "    optimizer=continued_optimizer,\n",
        "    scheduler=continued_scheduler,\n",
        "    device=device,\n",
        "    num_epochs=5,\n",
        "    patience=3,  # Lower patience as we expect smaller improvements\n",
        "\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b0_continued' # New checkpoint directory\n",
        ")"
      ],
      "metadata": {
        "id": "3lxroXIHh5hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqAlXrKcoxC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iSfz5eRHh58p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2418f3d6"
      },
      "source": [
        "### **1. Load EfficientNet-B1 Model**\n",
        "\n",
        "First, we'll load the `efficientnet_b1` model with its default pretrained weights from ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n"
      ],
      "metadata": {
        "id": "EZkHFzq6oz38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
        "transform = weights.transforms()\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize first\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Zoomed-in crops\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ConvNeXt pretrained on ImageNet\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "4z-1bk-4o1JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root=filtered_train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=filtered_test_dir, transform=val_transform)\n",
        "\n",
        "# Calculate class counts\n",
        "class_counts = [0] * len(train_dataset.classes)\n",
        "for _, label in train_dataset.samples:\n",
        "    class_counts[label] += 1\n",
        "\n",
        "# Weighted sampling\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "sample_weights = class_weights[train_dataset.targets]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "zSvKGs1Yo2io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = convnext_tiny(weights=weights)\n",
        "model = model.to(device)\n",
        "\n",
        "# Replace classifier (6 classes)\n",
        "in_features = model.classifier[2].in_features\n",
        "model.classifier[2] = nn.Linear(in_features, 6).to(device)\n"
      ],
      "metadata": {
        "id": "zNvlTGNGo3_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze last two feature blocks\n",
        "for layer in list(model.features.children())[-2:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Unfreeze classifier\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "l4VU2fwgpOGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.features.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n"
      ],
      "metadata": {
        "id": "OLgiYRQupcUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10, patience=5, checkpoint_dir=None):\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_loss, val_correct = 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            if checkpoint_dir:\n",
        "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "wQrkyWvFpei8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_and_validate(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    num_epochs=20,\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/convnext_tiny_checkpoint'\n",
        ")\n"
      ],
      "metadata": {
        "id": "-X4OLGUepgNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model weights\n",
        "model_path = \"/kaggle/working/convnext_fer2013.pth\" # Save to the working directory\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "K7AWlUFppiNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(model_path)\n"
      ],
      "metadata": {
        "id": "EtKa9BBt5EuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "model.to(device) # Move the model to the correct device\n",
        "\n",
        "# Run inference on validation set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device) # Move inputs to the correct device\n",
        "        labels = labels.to(device) # Move labels to the correct device\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(all_labels, all_preds, target_names=filtered_class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=filtered_class_names, yticklabels=filtered_class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LaCv0N7z5OmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Normalized Confusion Matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0l1FBkGw5RIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}