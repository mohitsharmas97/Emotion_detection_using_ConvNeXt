{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkar-hue/Emotion_detection_using_ConvNeXt/blob/main/fer_using_ConvNeXt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3KmsaNXpIJo"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /kaggle/input/fer2013/"
      ],
      "metadata": {
        "id": "t_COIqgDrCwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "r-Nm3MgYrEc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "PdIP7KfSrGII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through(path)"
      ],
      "metadata": {
        "id": "y8bAM2IDrKc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "YMFrvtxFrMVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/kaggle/input/fer2013/train'\n",
        "test_dir = '/kaggle/input/fer2013/test'\n"
      ],
      "metadata": {
        "id": "3sqB5ZCurOeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "DEwNzbLMrqYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For training with augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# For testing (no augmentation)\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "OSgK4-jOrl52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n"
      ],
      "metadata": {
        "id": "a5nntFY-rndm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "Jq3_hvSzrwAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.classes\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "id": "uns5418Yrygp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_dataset.classes\n",
        "\n",
        "class_name"
      ],
      "metadata": {
        "id": "c8LoArrfr06a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_idx = train_dataset.class_to_idx\n",
        "\n",
        "class_idx"
      ],
      "metadata": {
        "id": "Rx2HYzU6r5r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "RsgliUrGsAA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "weights = torchvision.models.EfficientNet_B3_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b3(weights=weights)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Qmi6DVAmr7rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze more layers\n",
        "for layer in list(model.features)[-5:]: # Try -8 or -10 instead of -5\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True"
      ],
      "metadata": {
        "id": "6UY_u9par-xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "\n",
        "output_shape = len(train_dataset.classes)\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.3, inplace=True),\n",
        "    torch.nn.Linear(in_features=1536,\n",
        "                    out_features=output_shape,\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "id": "PePDgEuSsHSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)"
      ],
      "metadata": {
        "id": "1IPWH5U1sJKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=2\n",
        ")"
      ],
      "metadata": {
        "id": "I5B4rJYUsOCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device,\n",
        "               scheduler: torch.optim.lr_scheduler._LRScheduler = None) -> Tuple[float, float]:\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() * X.size(0)  # Scale loss by batch size\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(loss)  # Step the scheduler if provided\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"LR: {current_lr:.6f}\")\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "    train_loss /= total_samples  # Normalize by total dataset size\n",
        "    train_acc /= total_samples  # Normalize accuracy\n",
        "\n",
        "    return train_loss, train_acc"
      ],
      "metadata": {
        "id": "uXZksREbsRrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "fipTYNb0sV67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       criterion,\n",
        "                       optimizer,\n",
        "                       device,\n",
        "                       num_epochs=50,\n",
        "                       patience=5,\n",
        "                       checkpoint_dir='./checkpoints',\n",
        "                       scheduler=None): # Add scheduler argument\n",
        "    \"\"\"\n",
        "    Train and validate the model with early stopping and checkpointing\n",
        "\n",
        "    Args:\n",
        "    - model: PyTorch model\n",
        "    - train_loader: DataLoader for training data\n",
        "    - val_loader: DataLoader for validation data\n",
        "    - criterion: Loss function\n",
        "    - optimizer: Optimizer\n",
        "    - device: Computing device (cuda/cpu)\n",
        "    - num_epochs: Maximum number of training epochs\n",
        "    - patience: Number of epochs with no improvement after which training will be stopped\n",
        "    - checkpoint_dir: Directory to save model checkpoints\n",
        "    - scheduler: (Optional) Learning rate scheduler\n",
        "    \"\"\"\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Training history tracking\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_acc = 0, 0\n",
        "\n",
        "        train_progress_bar = tqdm(train_loader,\n",
        "                                  desc=f'Epoch {epoch+1}/{num_epochs}',\n",
        "                                  unit='batch')\n",
        "\n",
        "        for batch, (X, y) in enumerate(train_progress_bar):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute metrics\n",
        "            train_loss += loss.item()\n",
        "            train_pred = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "            train_acc += (train_pred == y).float().mean().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            train_progress_bar.set_postfix({\n",
        "                'Train Loss': loss.item(),\n",
        "                'Train Acc': train_acc / (batch + 1)\n",
        "            })\n",
        "\n",
        "        # Average epoch metrics\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_acc = 0, 0\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_pred = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "                val_acc += (val_pred == y).float().mean().item()\n",
        "\n",
        "        # Average validation metrics\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc /= len(val_loader)\n",
        "\n",
        "        # Store history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Step the scheduler with the validation loss\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "            print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping and model checkpointing\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss\n",
        "            }, os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "            break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "mPC2H2afsXcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_and_validate(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        num_epochs=6,\n",
        "        patience=3,\n",
        "        checkpoint_dir='/kaggle/working/checkpoints'\n",
        "    )"
      ],
      "metadata": {
        "id": "kwxMlieHsZL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "class_counts = [3995, 436, 4097, 7215, 4965, 4830, 3171]  # from your walk_through\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "sample_weights = class_weights[train_dataset.targets]\n",
        "\n",
        "# Create sampler\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "Qup9nBI6sbRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, sampler=sampler)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "FJ-hXjZVyRvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model modification (increase dropout)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),  # increased from 0.3\n",
        "    nn.Linear(1280, output_shape)\n",
        ").to(device)\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "lzhsrTJOyvye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "zj7AnwSLywaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_and_validate(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        num_epochs=15,\n",
        "        patience=7,\n",
        "        checkpoint_dir='/kaggle/working/checkpoints'\n",
        "    )"
      ],
      "metadata": {
        "id": "y7fcpJqTzHOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPUQEY_uzSVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2b8e00d"
      },
      "source": [
        "# Task\n",
        "Remove the 'disgust' class from the dataset, adjust the model architecture accordingly, and retrain the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c37ae1"
      },
      "source": [
        "## Filter datasets\n",
        "\n",
        "### Subtask:\n",
        "Create new datasets for both training and testing that exclude the 'disgust' class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b650890"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create the new directories for the filtered data and then define a function to copy the images, excluding the 'disgust' class, to these new directories, as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba6a00af"
      },
      "source": [
        "import shutil\n",
        "\n",
        "# 1. Define paths to original directories\n",
        "original_train_dir = '/kaggle/input/fer2013/train'\n",
        "original_test_dir = '/kaggle/input/fer2013/test'\n",
        "\n",
        "# 2. Create new directories\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "os.makedirs(filtered_train_dir, exist_ok=True)\n",
        "os.makedirs(filtered_test_dir, exist_ok=True)\n",
        "\n",
        "# 3. Define classes to keep\n",
        "classes_to_keep = ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# 4. Write a function to copy filtered data\n",
        "def filter_and_copy_data(original_dir, new_dir, classes):\n",
        "    for class_name in classes:\n",
        "        # Create class subdirectory in the new directory\n",
        "        new_class_dir = os.path.join(new_dir, class_name)\n",
        "        os.makedirs(new_class_dir, exist_ok=True)\n",
        "\n",
        "        # Path to the original class subdirectory\n",
        "        original_class_dir = os.path.join(original_dir, class_name)\n",
        "\n",
        "        # Copy all images from the original to the new directory\n",
        "        for filename in os.listdir(original_class_dir):\n",
        "            shutil.copy(os.path.join(original_class_dir, filename), new_class_dir)\n",
        "\n",
        "# 5. Call the function for both training and testing datasets\n",
        "filter_and_copy_data(original_train_dir, filtered_train_dir, classes_to_keep)\n",
        "filter_and_copy_data(original_test_dir, filtered_test_dir, classes_to_keep)\n",
        "\n",
        "print(\"Filtered datasets created successfully.\")\n",
        "walk_through(filtered_train_dir)\n",
        "walk_through(filtered_test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ed5e38b"
      },
      "source": [
        "## Update class information\n",
        "\n",
        "### Subtask:\n",
        "Update the class names and class-to-index mappings to reflect the removal of the 'disgust' class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9658fdd"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a new ImageFolder dataset for the filtered training data, then extract the class names and class-to-index mapping, and finally update the output shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d71cca0"
      },
      "source": [
        "# 1. Create a new ImageFolder dataset for the filtered training data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_train_dataset = datasets.ImageFolder(root=filtered_train_dir, transform=train_transforms)\n",
        "\n",
        "# 2. Extract the class names and class-to-index mapping\n",
        "filtered_class_names = filtered_train_dataset.classes\n",
        "filtered_class_idx = filtered_train_dataset.class_to_idx\n",
        "\n",
        "print(\"Filtered Classes:\", filtered_class_names)\n",
        "print(\"Filtered Class Index Mapping:\", filtered_class_idx)\n",
        "\n",
        "# 3. Update the output_shape variable\n",
        "output_shape = len(filtered_class_names)\n",
        "print(\"Updated output shape:\", output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6dc01fd"
      },
      "source": [
        "## Recreate sampler and dataloaders\n",
        "\n",
        "### Subtask:\n",
        "Recreate the `WeightedRandomSampler` and `DataLoaders` for the updated, filtered datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "329a902d"
      },
      "source": [
        "**Reasoning**:\n",
        "Recreate the WeightedRandomSampler and DataLoaders for the updated, filtered datasets using the instructions provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152166f9"
      },
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# 1. Get the class counts from the filtered_train_dataset\n",
        "# The targets attribute of ImageFolder dataset contains the class index for each sample\n",
        "filtered_class_counts = [0] * len(filtered_class_names)\n",
        "for target in filtered_train_dataset.targets:\n",
        "    filtered_class_counts[target] += 1\n",
        "\n",
        "print(\"Filtered Class Counts:\", filtered_class_counts)\n",
        "\n",
        "# 2. Calculate the class weights based on the new class counts\n",
        "filtered_class_weights = 1. / torch.tensor(filtered_class_counts, dtype=torch.float)\n",
        "filtered_sample_weights = filtered_class_weights[filtered_train_dataset.targets]\n",
        "\n",
        "# 3. Create a WeightedRandomSampler using these new weights and the filtered_train_dataset.targets\n",
        "filtered_sampler = WeightedRandomSampler(\n",
        "    weights=filtered_sample_weights,\n",
        "    num_samples=len(filtered_sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# 4. Create a new DataLoader for the filtered training data, using the new sampler.\n",
        "# Ensure shuffle is set to False since the sampler handles the shuffling.\n",
        "filtered_train_loader = DataLoader(filtered_train_dataset, batch_size=32, shuffle=False, sampler=filtered_sampler, num_workers=2)\n",
        "\n",
        "# 5. Create a new DataLoader for the filtered test data.\n",
        "# You can use the filtered_test_dir to create a new ImageFolder dataset for this.\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "filtered_test_dataset = datasets.ImageFolder(root=filtered_test_dir, transform=test_transforms)\n",
        "filtered_test_loader = DataLoader(filtered_test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Filtered train and test DataLoaders created with WeightedRandomSampler.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb94ba90"
      },
      "source": [
        "## Adjust model architecture\n",
        "\n",
        "### Subtask:\n",
        "The final layer of the model will be modified to output 6 classes instead of 7.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8bc509"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the classifier layer of the model to match the updated output shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ceef27"
      },
      "source": [
        "# Access the current model architecture and modify the classifier\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.5), # Keep the increased dropout from previous attempt\n",
        "    torch.nn.Linear(in_features=1280, # Input features remain the same as the base model's output\n",
        "                    out_features=output_shape, # Output features adjusted to the new number of classes (6)\n",
        "                    bias=True)\n",
        ").to(device) # Ensure the modified classifier is on the correct device\n",
        "\n",
        "print(f\"Model classifier updated to output {output_shape} classes.\")\n",
        "print(model.classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea48d1bb"
      },
      "source": [
        "## Retrain the model\n",
        "\n",
        "### Subtask:\n",
        "Retrain the model with the updated datasets, dataloaders, and model architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a910b94"
      },
      "source": [
        "**Reasoning**:\n",
        "Retrain the model using the updated dataloaders and model architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a4dc3e4"
      },
      "source": [
        "history_filtered = train_and_validate(\n",
        "    model=model,\n",
        "    train_loader=filtered_train_loader,\n",
        "    val_loader=filtered_test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    num_epochs=15,\n",
        "    patience=7,\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_filtered' # Use a different checkpoint directory\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mp5V7f6C6yK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wIjQ9-t7LRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d9cd0ab"
      },
      "source": [
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classifier\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUqahCO2_5Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9001415d"
      },
      "source": [
        "### **1. Load EfficientNet-B3 Model**\n",
        "\n",
        "First, we'll load the `efficientnet_b3` model with its default pretrained weights from ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f594dcb1"
      },
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load EfficientNet-B3 with default weights and move it to the selected device\n",
        "weights_b3 = torchvision.models.EfficientNet_B3_Weights.DEFAULT\n",
        "model_b3 = torchvision.models.efficientnet_b3(weights=weights_b3)\n",
        "model_b3 = model_b3.to(device)\n",
        "\n",
        "print(\"EfficientNet-B3 model loaded successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "424f057b"
      },
      "source": [
        "### **2. Create Transforms for EfficientNet-B3**\n",
        "\n",
        "Pre-trained models require specific input transformations (like image size and normalization values). We can get the recommended transforms directly from the weights object. `EfficientNet-B3` expects 300x300 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ff90fe8"
      },
      "source": [
        "# Get the appropriate transforms for the B3 model\n",
        "transforms_b3 = weights_b3.transforms()\n",
        "\n",
        "print(\"Transforms for EfficientNet-B3 created:\")\n",
        "display(transforms_b3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fca5a5d1"
      },
      "source": [
        "### **3. Recreate Datasets and DataLoaders**\n",
        "\n",
        "Now we'll create new datasets and dataloaders using the filtered data directories and the new `transforms_b3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d50eae7"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torch\n",
        "\n",
        "# Define the paths to the filtered data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "\n",
        "# Create new datasets using the B3 transforms\n",
        "train_dataset_b3 = datasets.ImageFolder(root=filtered_train_dir, transform=transforms_b3)\n",
        "test_dataset_b3 = datasets.ImageFolder(root=filtered_test_dir, transform=transforms_b3)\n",
        "\n",
        "# Correctly calculate class counts from the dataset\n",
        "filtered_class_counts = [0] * len(train_dataset_b3.classes)\n",
        "for _, index in train_dataset_b3.samples:\n",
        "    filtered_class_counts[index] += 1\n",
        "\n",
        "# Recreate the sampler for the new training dataset to handle class imbalance\n",
        "filtered_class_weights = 1. / torch.tensor(filtered_class_counts, dtype=torch.float)\n",
        "filtered_sample_weights = filtered_class_weights[train_dataset_b3.targets]\n",
        "\n",
        "sampler_b3 = WeightedRandomSampler(\n",
        "    weights=filtered_sample_weights,\n",
        "    num_samples=len(filtered_sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Create new DataLoaders for the B3 model\n",
        "train_loader_b3 = DataLoader(train_dataset_b3, batch_size=32, sampler=sampler_b3, num_workers=2)\n",
        "test_loader_b3 = DataLoader(test_dataset_b3, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"New DataLoaders for EfficientNet-B3 created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b03d1f8a"
      },
      "source": [
        "### **4. Freeze Layers and Rebuild Classifier**\n",
        "\n",
        "As requested, we will freeze all the convolutional layers and replace the classifier head with a new one suited for our 6-class problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07014099"
      },
      "source": [
        "# Freeze all parameters in the model\n",
        "for param in model_b3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Get the number of input features for the B3 classifier\n",
        "in_features_b3 = model_b3.classifier[1].in_features\n",
        "output_shape_filtered = 6 # 6 classes after removing 'disgust'\n",
        "\n",
        "# Replace the classifier and unfreeze its parameters so they can be trained\n",
        "model_b3.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.3, inplace=True),\n",
        "    torch.nn.Linear(\n",
        "        in_features=in_features_b3,\n",
        "        out_features=output_shape_filtered,\n",
        "        bias=True\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "print(\"All layers frozen. New classifier for 6 classes created and unfrozen.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39b17778"
      },
      "source": [
        "### **5. Configure Optimizer and Retrain**\n",
        "\n",
        "Finally, we'll create a new optimizer that only targets the parameters of the newly created classifier and then begin the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cd330f4"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# The filter ensures we only pass the trainable (unfrozen) parameters to the optimizer\n",
        "optimizer_b3 = optim.Adam(filter(lambda p: p.requires_grad, model_b3.parameters()), lr=0.001)\n",
        "\n",
        "# Retrain the model on the filtered data\n",
        "history_b3 = train_and_validate(\n",
        "    model=model_b3,\n",
        "    train_loader=train_loader_b3,\n",
        "    val_loader=test_loader_b3,\n",
        "    criterion=criterion, # Reusing the previously defined loss function\n",
        "    optimizer=optimizer_b3,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b3_filtered' # New checkpoint directory\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVnULOXvBDeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bca45656"
      },
      "source": [
        "### **1. Load EfficientNet-B0 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80e8a6ce"
      },
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load EfficientNet-B0 with default weights and move it to the selected device\n",
        "weights_b0 = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_b0 = torchvision.models.efficientnet_b0(weights=weights_b0)\n",
        "model_b0 = model_b0.to(device)\n",
        "\n",
        "print(\"EfficientNet-B0 model loaded successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2c58ffe"
      },
      "source": [
        "### **2. Create Transforms for EfficientNet-B0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "953bcdd8"
      },
      "source": [
        "# Get the appropriate transforms for the B0 model\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transforms_b0 = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "\n",
        "transforms_b0 = weights_b0.transforms()\n",
        "\n",
        "print(\"Transforms for EfficientNet-B0 created:\")\n",
        "display(transforms_b0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d59a3ea4"
      },
      "source": [
        "### **3. Recreate Datasets and DataLoaders for Filtered Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bace1d48"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torch\n",
        "\n",
        "# Define the paths to the filtered data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "\n",
        "# Create new datasets using the B0 transforms\n",
        "train_dataset_b0 = datasets.ImageFolder(root=filtered_train_dir, transform=train_transforms_b0)\n",
        "test_dataset_b0 = datasets.ImageFolder(root=filtered_test_dir, transform=transforms_b0)\n",
        "\n",
        "# Correctly calculate class counts from the dataset\n",
        "filtered_class_counts = [0] * len(train_dataset_b0.classes)\n",
        "for _, index in train_dataset_b0.samples:\n",
        "    filtered_class_counts[index] += 1\n",
        "\n",
        "# Recreate the sampler for the new training dataset to handle class imbalance\n",
        "filtered_class_weights = 1. / torch.tensor(filtered_class_counts, dtype=torch.float)\n",
        "filtered_sample_weights = filtered_class_weights[train_dataset_b0.targets]\n",
        "\n",
        "sampler_b0 = WeightedRandomSampler(\n",
        "    weights=filtered_sample_weights,\n",
        "    num_samples=len(filtered_sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Create new DataLoaders for the B0 model\n",
        "train_loader_b0 = DataLoader(train_dataset_b0, batch_size=32, sampler=sampler_b0, num_workers=2)\n",
        "test_loader_b0 = DataLoader(test_dataset_b0, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"New DataLoaders for EfficientNet-B0 created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74b4dfc1"
      },
      "source": [
        "### **4. Unfreeze Last 10 Layers and Rebuild Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7508e1bd"
      },
      "source": [
        "# Freeze all parameters in the model\n",
        "for param in model_b0.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Get the number of input features for the B0 classifier\n",
        "in_features_b0 = model_b0.classifier[1].in_features\n",
        "output_shape_filtered = 6 # 6 classes after removing 'disgust'\n",
        "\n",
        "# Replace the classifier and ensure its parameters are trainable\n",
        "model_b0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.5, inplace=True), # Adjusted dropout\n",
        "    torch.nn.Linear(\n",
        "        in_features=in_features_b0,\n",
        "        out_features=output_shape_filtered,\n",
        "        bias=True\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "print(\"All feature layers frozen. New classifier created and unfrozen.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f65b4fa"
      },
      "source": [
        "### **5. Configure Optimizer and Retrain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eec425de"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# The optimizer now only gets the parameters of the classifier\n",
        "optimizer_b0 = optim.Adam(model_b0.classifier.parameters(), lr=0.001) # Only pass classifier parameters\n",
        "\n",
        "# Define the scheduler\n",
        "scheduler_b0 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_b0, 'min', patience=2, verbose=True)\n",
        "\n",
        "# Retrain the model on the filtered data\n",
        "history_b0 = train_and_validate(\n",
        "    model=model_b0,\n",
        "    train_loader=train_loader_b0,\n",
        "    val_loader=test_loader_b0,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_b0,\n",
        "    scheduler=scheduler_b0,\n",
        "    device=device,\n",
        "    num_epochs=15, # Increased epochs for fine-tuning the classifier\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b0_classifier_only' # New checkpoint directory\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the paths to the filtered data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "\n",
        "# Get the appropriate transforms for the B0 model\n",
        "weights_b0 = models.EfficientNet_B0_Weights.DEFAULT\n",
        "transforms_b0 = weights_b0.transforms()\n",
        "\n",
        "# Create new datasets using the B0 transforms\n",
        "train_dataset_b0 = datasets.ImageFolder(root=filtered_train_dir, transform=transforms_b0)\n",
        "test_dataset_b0 = datasets.ImageFolder(root=filtered_test_dir, transform=transforms_b0)\n",
        "\n",
        "# Correctly calculate class counts from the dataset\n",
        "filtered_class_counts = [0] * len(train_dataset_b0.classes)\n",
        "for _, index in train_dataset_b0.samples:\n",
        "    filtered_class_counts[index] += 1\n",
        "\n",
        "# Recreate the sampler for the new training dataset to handle class imbalance\n",
        "filtered_class_weights = 1. / torch.tensor(filtered_class_counts, dtype=torch.float)\n",
        "filtered_sample_weights = filtered_class_weights[train_dataset_b0.targets]\n",
        "\n",
        "sampler_b0 = WeightedRandomSampler(\n",
        "    weights=filtered_sample_weights,\n",
        "    num_samples=len(filtered_sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Create new DataLoaders for the B0 model\n",
        "train_loader_b0 = DataLoader(train_dataset_b0, batch_size=32, sampler=sampler_b0, num_workers=2)\n",
        "test_loader_b0 = DataLoader(test_dataset_b0, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load the model\n",
        "model_b0 = models.efficientnet_b0(weights=weights_b0)\n",
        "model_b0 = model_b0.to(device)\n",
        "\n",
        "# Freeze all parameters in the model first\n",
        "for param in model_b0.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last 5 layers of the features\n",
        "for layer in list(model_b0.features)[-5:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Get the number of input features for the B0 classifier\n",
        "in_features_b0 = model_b0.classifier[1].in_features\n",
        "output_shape_filtered = 6 # 6 classes after removing 'disgust'\n",
        "\n",
        "# Replace the classifier and unfreeze its parameters so they can be trained\n",
        "model_b0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.5, inplace=True),  # Increased dropout\n",
        "    torch.nn.Linear(\n",
        "        in_features=in_features_b0,\n",
        "        out_features=output_shape_filtered,\n",
        "        bias=True\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "# The filter ensures we only pass the trainable (unfrozen) parameters to the optimizer\n",
        "optimizer_b0 = optim.Adam(filter(lambda p: p.requires_grad, model_b0.parameters()), lr=0.0001, weight_decay=1e-4) # Added weight decay\n",
        "\n",
        "# Define the scheduler\n",
        "scheduler_b0 = ReduceLROnPlateau(optimizer_b0, 'min', patience=2, verbose=True)\n",
        "\n",
        "# Retrain the model on the filtered data\n",
        "# history_b0 = train_and_validate(\n",
        "#     model=model_b0,\n",
        "#     train_loader=train_loader_b0,\n",
        "#     val_loader=test_loader_b0,\n",
        "#     criterion=criterion, # Reusing the previously defined loss function\n",
        "#     optimizer=optimizer_b0,\n",
        "#     scheduler=scheduler_b0, # Pass the scheduler\n",
        "#     device=device,\n",
        "#     num_epochs=10,\n",
        "#     patience=5,\n",
        "#     checkpoint_dir='/kaggle/working/checkpoints_b0_filtered' # New checkpoint directory\n",
        "# )"
      ],
      "metadata": {
        "id": "Ixi0WqDrJOik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function with optional label smoothing\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n"
      ],
      "metadata": {
        "id": "FLmcIQE7i_u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# --- NEW STRATEGY: Deeper fine-tuning ---\n",
        "\n",
        "# 1. Freeze all parameters in the model first\n",
        "for param in model_b0.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. Unfreeze the classifier AND the last few convolutional blocks.\n",
        "# This allows the model to adapt its deeper feature detectors to our specific dataset.\n",
        "# We'll unfreeze more layers than before.\n",
        "for layer in list(model_b0.features)[-4:]: # Unfreezing the last 4 blocks\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Also, ensure the classifier is unfrozen\n",
        "for param in model_b0.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. Set up the optimizer with DIFFERENT learning rates. This is the key change.\n",
        "# The deep convolutional layers (features) get a very small learning rate (lr=1e-5).\n",
        "# The brand-new classifier gets a larger learning rate (lr=1e-4).\n",
        "optimizer_b0 = optim.Adam([\n",
        "    {'params': model_b0.features.parameters(), 'lr': 1e-5},\n",
        "    {'params': model_b0.classifier.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4) # Keep weight decay for regularization\n",
        "\n",
        "# 4. Set up the scheduler to monitor the optimizer\n",
        "scheduler_b0 = ReduceLROnPlateau(optimizer_b0, 'min', patience=2, verbose=True)\n",
        "\n",
        "# 5. Retrain the model with the new optimizer setup\n",
        "history_b0 = train_and_validate(\n",
        "    model=model_b0,\n",
        "    train_loader=train_loader_b0,\n",
        "    val_loader=test_loader_b0,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_b0,\n",
        "    scheduler=scheduler_b0,\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b0_finetuned' # New directory\n",
        ")"
      ],
      "metadata": {
        "id": "k-DoWZbiYqMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# 1. Save the current state of the model after 10 epochs\n",
        "checkpoint_path_10_epochs = '/kaggle/working/model_b0_10_epochs.pth'\n",
        "torch.save(model_b0.state_dict(), checkpoint_path_10_epochs)\n",
        "print(f\"Model after 10 epochs saved to: {checkpoint_path_10_epochs}\")\n"
      ],
      "metadata": {
        "id": "3ZKONxNbhodI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YO0LX4rTh4o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEyhSBEDhouO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcbde1b7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/kaggle/working/model_b0_10_epochs.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nContinuing training with a lower learning rate...\")\n",
        "continued_optimizer = optim.Adam([\n",
        "    {'params': model_b0.features.parameters(), 'lr': 2e-6},  # Was 1e-5\n",
        "    {'params': model_b0.classifier.parameters(), 'lr': 2e-5}   # Was 1e-4\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# 3. Set up a new scheduler for the new optimizer\n",
        "continued_scheduler = ReduceLROnPlateau(continued_optimizer, 'min', patience=2, verbose=True)\n",
        "\n",
        "# 4. Train for 5 more epochs\n",
        "history_continued = train_and_validate(\n",
        "    model=model_b0,\n",
        "    train_loader=train_loader_b0,\n",
        "    val_loader=test_loader_b0,\n",
        "    criterion=criterion,\n",
        "    optimizer=continued_optimizer,\n",
        "    scheduler=continued_scheduler,\n",
        "    device=device,\n",
        "    num_epochs=5,\n",
        "    patience=3,  # Lower patience as we expect smaller improvements\n",
        "\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b0_continued' # New checkpoint directory\n",
        ")"
      ],
      "metadata": {
        "id": "3lxroXIHh5hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqAlXrKcoxC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iSfz5eRHh58p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2418f3d6"
      },
      "source": [
        "### **1. Load EfficientNet-B1 Model**\n",
        "\n",
        "First, we'll load the `efficientnet_b1` model with its default pretrained weights from ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4591580"
      },
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load EfficientNet-B1 with default weights and move it to the selected device\n",
        "weights_b1 = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n",
        "model_b1 = torchvision.models.efficientnet_b1(weights=weights_b1)\n",
        "model_b1 = model_b1.to(device)\n",
        "\n",
        "print(\"EfficientNet-B1 model loaded successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ab18cb"
      },
      "source": [
        "### **2. Create Transforms for EfficientNet-B1**\n",
        "\n",
        "Pre-trained models require specific input transformations (like image size and normalization values). We can get the recommended transforms directly from the weights object. `EfficientNet-B1` expects 240x240 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8a07d7e"
      },
      "source": [
        "# Get the appropriate transforms for the B1 model\n",
        "transforms_b1 = weights_b1.transforms()\n",
        "\n",
        "print(\"Transforms for EfficientNet-B1 created:\")\n",
        "display(transforms_b1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c22af04"
      },
      "source": [
        "### **3. Recreate Datasets and DataLoaders for Filtered Data**\n",
        "\n",
        "Now we'll create new datasets and dataloaders using the filtered data directories and the new `transforms_b1`. We will reuse the `filtered_class_counts` and `filtered_sample_weights` calculated earlier since the number of classes and samples in each class remains the same for the filtered dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b40c3318"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torch\n",
        "\n",
        "# Define the paths to the filtered data\n",
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n",
        "\n",
        "# Create new datasets using the B1 transforms\n",
        "train_dataset_b1 = datasets.ImageFolder(root=filtered_train_dir, transform=transforms_b1)\n",
        "test_dataset_b1 = datasets.ImageFolder(root=filtered_test_dir, transform=transforms_b1)\n",
        "\n",
        "# Recreate the sampler for the new training dataset to handle class imbalance\n",
        "# We can reuse filtered_class_weights and filtered_sample_weights from the previous B0 run\n",
        "sampler_b1 = WeightedRandomSampler(\n",
        "    weights=filtered_sample_weights,\n",
        "    num_samples=len(filtered_sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# Create new DataLoaders for the B1 model\n",
        "train_loader_b1 = DataLoader(train_dataset_b1, batch_size=32, sampler=sampler_b1, num_workers=2)\n",
        "test_loader_b1 = DataLoader(test_dataset_b1, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"New DataLoaders for EfficientNet-B1 created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "832cda91"
      },
      "source": [
        "### **4. Unfreeze Last 4 Blocks and Rebuild Classifier**\n",
        "\n",
        "We will follow the same fine-tuning strategy as with the B0 model: freeze the majority of the feature extractor, unfreeze the last 4 convolutional blocks and the classifier, and train these layers with different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50766dbc"
      },
      "source": [
        "# Freeze all parameters in the model first\n",
        "for param in model_b1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last 4 blocks of the features\n",
        "for layer in list(model_b1.features)[-4:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Get the number of input features for the B1 classifier\n",
        "in_features_b1 = model_b1.classifier[1].in_features\n",
        "output_shape_filtered = 6 # 6 classes after removing 'disgust'\n",
        "\n",
        "# Replace the classifier and unfreeze its parameters so they can be trained\n",
        "model_b1.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.5, inplace=True),  # Increased dropout\n",
        "    torch.nn.Linear(\n",
        "        in_features=in_features_b1,\n",
        "        out_features=output_shape_filtered,\n",
        "        bias=True\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "print(\"All feature layers frozen except the last 4 blocks. New classifier created and unfrozen.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ca5af5"
      },
      "source": [
        "### **5. Configure Optimizer with Layer-wise Learning Rates and Retrain**\n",
        "\n",
        "We will use the same strategy of applying different learning rates to the feature extractor (lower LR) and the classifier (higher LR). We will also include the `ReduceLROnPlateau` scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f93063b"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Set up the optimizer with DIFFERENT learning rates for features and classifier\n",
        "optimizer_b1 = optim.Adam([\n",
        "    {'params': model_b1.features.parameters(), 'lr': 1e-5}, # Lower LR for features\n",
        "    {'params': model_b1.classifier.parameters(), 'lr': 1e-4} # Higher LR for classifier\n",
        "], weight_decay=1e-4) # Keep weight decay for regularization\n",
        "\n",
        "# Define the scheduler\n",
        "scheduler_b1 = ReduceLROnPlateau(optimizer_b1, 'min', patience=2, verbose=True)\n",
        "\n",
        "# Retrain the model on the filtered data\n",
        "history_b1 = train_and_validate(\n",
        "    model=model_b1,\n",
        "    train_loader=train_loader_b1,\n",
        "    val_loader=test_loader_b1,\n",
        "    criterion=criterion, # Reusing the previously defined loss function\n",
        "    optimizer=optimizer_b1,\n",
        "    scheduler=scheduler_b1, # Pass the scheduler\n",
        "    device=device,\n",
        "    num_epochs=10,\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/checkpoints_b1_finetuned' # New directory\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "wSf5fcMrox__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "6l5h40h6oyYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_train_dir = '/kaggle/working/train_filtered'\n",
        "filtered_test_dir = '/kaggle/working/test_filtered'\n"
      ],
      "metadata": {
        "id": "EZkHFzq6oz38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "weights = ConvNeXt_Tiny_Weights.DEFAULT\n",
        "transform = weights.transforms()\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),  # Resize first\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Zoomed-in crops\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ConvNeXt pretrained on ImageNet\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "4z-1bk-4o1JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(root=filtered_train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=filtered_test_dir, transform=val_transform)\n",
        "\n",
        "# Calculate class counts\n",
        "class_counts = [0] * len(train_dataset.classes)\n",
        "for _, label in train_dataset.samples:\n",
        "    class_counts[label] += 1\n",
        "\n",
        "# Weighted sampling\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "sample_weights = class_weights[train_dataset.targets]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "zSvKGs1Yo2io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = convnext_tiny(weights=weights)\n",
        "model = model.to(device)\n",
        "\n",
        "# Replace classifier (6 classes)\n",
        "in_features = model.classifier[2].in_features\n",
        "model.classifier[2] = nn.Linear(in_features, 6).to(device)\n"
      ],
      "metadata": {
        "id": "zNvlTGNGo3_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze last two feature blocks\n",
        "for layer in list(model.features.children())[-2:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Unfreeze classifier\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "l4VU2fwgpOGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.features.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n"
      ],
      "metadata": {
        "id": "OLgiYRQupcUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=10, patience=5, checkpoint_dir=None):\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_loss, val_correct = 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            if checkpoint_dir:\n",
        "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "wQrkyWvFpei8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_and_validate(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    num_epochs=20,\n",
        "    patience=5,\n",
        "    checkpoint_dir='/kaggle/working/convnext_tiny_checkpoint'\n",
        ")\n"
      ],
      "metadata": {
        "id": "-X4OLGUepgNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model weights\n",
        "model_path = \"/kaggle/working/convnext_fer2013.pth\" # Save to the working directory\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "K7AWlUFppiNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(model_path)\n"
      ],
      "metadata": {
        "id": "EtKa9BBt5EuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "model.to(device) # Move the model to the correct device\n",
        "\n",
        "# Run inference on validation set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device) # Move inputs to the correct device\n",
        "        labels = labels.to(device) # Move labels to the correct device\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(all_labels, all_preds, target_names=filtered_class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=filtered_class_names, yticklabels=filtered_class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LaCv0N7z5OmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Normalized Confusion Matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0l1FBkGw5RIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}